{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "707974d3",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48154912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MeanAbsoluteError\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b869239",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('nigeria_houses_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551b4f39",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310a4c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying summary statistics of the dataset\n",
    "data.describe()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa01f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values in the dataset using isnull() and sum()\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab425dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec4ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting specific columns to the 'int64' data type\n",
    "\n",
    "data[['bedrooms', 'bathrooms', 'toilets', 'parking_space', 'price']] = data[['bedrooms', 'bathrooms', 'toilets', \n",
    "                                                                             'parking_space', 'price']].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d457e9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8231838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the unique values in the 'title' column of the DataFrame\n",
    "\n",
    "data.title.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f55e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the unique values in the 'title' column of the DataFrame\n",
    "\n",
    "data.town.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0aaddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f764c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Lagos dataset\n",
    "df = data[(data['state'] =='Lagos')]\n",
    "\n",
    "#creating a list of the categorical features\n",
    "cat_cols = [col for col in df.columns if df[col].dtype == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c6b02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4181d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use onehotencoding to preprocess and encode the cat features\n",
    "df_1= pd.get_dummies(df, columns = cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc369a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9017cbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7489bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the features and target variables\n",
    "\n",
    "target = df_1.price\n",
    "features = df_1.drop(['price', 'state_Lagos'], axis=1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3290e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splittng the dataset into training and testing sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1acb3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the validation sets\n",
    "\n",
    "X_val = X_train.sample(frac=0.2, random_state=0)\n",
    "y_val = y_train.sample(frac=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fb09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a StandardScaler for the input features (X)\n",
    "scaler_X = StandardScaler()\n",
    "\n",
    "# Fit and transform the training set\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing and validation sets using the same scaler\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "X_val_scaled = scaler_X.transform(X_val)\n",
    "\n",
    "# Creating a StandardScaler for the target variable\n",
    "scaler_y = StandardScaler()\n",
    "# Fit and transform the training set target variable\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# Transform the testing and validation sets target variable using the same scaler\n",
    "y_val_scaled = scaler_y.transform(y_val.values.reshape(-1, 1)).ravel()\n",
    "y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f090db13",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ca3a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the data by 'price' in descending order and select the top 10\n",
    "data_sorted = data.sort_values(by='price', ascending=False).head(10)\n",
    "\n",
    "# Extracting 'town' and 'price' columns\n",
    "town= data_sorted['town']\n",
    "price = data_sorted['price']\n",
    "\n",
    "# Creating a horizontal bar chart showing the most expensive houses in lagos and their locations\n",
    "plt.barh(town, price)\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Town')\n",
    "plt.title('Most Expensive Houses in Lagos')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f778c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Seaborn style to whitegrid\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "# Creating a scatter plot using Seaborn\n",
    "plt.figure(figsize=(18, 8))\n",
    "sns.scatterplot(x= 'title', y ='price', hue='bedrooms', data =data, palette='inferno', s=100)\n",
    "plt.title('The relationship between type of house, Nr. of bedrooms and the price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f071a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(x= 'bedrooms', y ='price', data =data, palette='inferno', s=100)\n",
    "plt.title('The relationship between Nr. of bedrooms and the price')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.scatterplot(x= 'bathrooms', y ='price', data =data, palette='inferno', s=100)\n",
    "plt.title('The relationship between Nr. of bathrooms and the price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25baf836",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.scatterplot(x= 'toilets', y ='price', data =data, palette='inferno', s=100)\n",
    "plt.title('The relationship between Nr. of toilets and the price')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.scatterplot(x= 'parking_space', y ='price', data =data, palette='inferno', s=100)\n",
    "plt.title('The relationship between Nr. of parking spaces and the price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb252af",
   "metadata": {},
   "source": [
    "# Summary of the Visualization\n",
    "\n",
    "Looking at the plots the price of houses in Lagos state doesn't seem to be affected by the number of bedrooms, bathrooms, toilets, or parking spaces, but mostly by the location."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60b0176",
   "metadata": {},
   "source": [
    "# Training Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35271fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the model\n",
    "model = Sequential([\n",
    "    Dense(units= 128, input_shape= (X_train_scaled.shape[1],), activation='relu'),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dense(units=16, activation='relu'),\n",
    "    Dense(1, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f6536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model\n",
    "optimizer= Adam(learning_rate= 0.001)\n",
    "model.compile(optimizer=optimizer, loss=MeanAbsoluteError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebca23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting/training the model\n",
    "model_history = model.fit(X_train_scaled, y_train_scaled, batch_size=56, epochs=250, \n",
    "                          verbose=0, validation_data=(X_val_scaled, y_val_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86febd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the training and validation losses\n",
    "\n",
    "model_history_df = pd.DataFrame(model_history.history)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot training & validation loss values\n",
    "\n",
    "plt.plot(model_history_df['loss'], label='Train')\n",
    "plt.plot(model_history_df['val_loss'], label='Validation')\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc5a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making predictions with the model\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0abf2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unscaling the predicted values\n",
    "y_pred_unscaled = scaler_y.inverse_transform(y_pred).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33480035",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_unscaled.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e105ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ac0fdc",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edae6e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the coefficient of determination using r2_score\n",
    "eval_r2 = r2_score(y_test, y_pred_unscaled)\n",
    "eval_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4559407",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6840a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['price', 'state'], axis = 1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452eb4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the training and testing sets\n",
    "\n",
    "X_train_2, X_test_all, y_train_2, y_test_all = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Creating the validation sets\n",
    "\n",
    "X_test_2, X_val_2, y_test_2, y_val_2 = train_test_split(X_test_all, y_test_all, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df60bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(X.dtypes)\n",
    "print(X_train_2[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4621516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the nunerical and categorical features\n",
    "\n",
    "num_features = X.select_dtypes(include=['int64']).columns\n",
    "cat_features = X.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90cf6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the preprocessing steps\n",
    "\n",
    "numerical_transformer = StandardScaler(with_mean=False)\n",
    "\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore')),\n",
    "    ('scaler', StandardScaler(with_mean=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c20d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the preprocessor, combining the transformation steps for numerical and cat features\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, num_features),\n",
    "    ('cat', cat_transformer, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381b0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the model using a pipepline and randomforest regressor\n",
    "\n",
    "model_2 = Pipeline(steps=[\n",
    "    ('preprocess', preprocessor),\n",
    "    ('model', RandomForestRegressor(\n",
    "        n_estimators=250,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        max_features='1.0',\n",
    "        random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdeadb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting the model\n",
    "\n",
    "model_2.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8baab06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the target feature\n",
    "scale_y_val = StandardScaler(with_mean=False)\n",
    "y_val_scl = scale_y_val.fit_transform(y_val_2.values.reshape(-1, 1)).ravel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da9a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_prices(inputs):\n",
    "    result = model_2.predict(inputs)\n",
    "    return scale_y_val.inverse_transform(result.reshape(-1, 1))\n",
    "\n",
    "#making predictions\n",
    "model_2_preds = predict_prices(X_val_2)\n",
    "model_2_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c038cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c52659",
   "metadata": {},
   "source": [
    "# Evaluating Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf4001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the mean squared error\n",
    "mse_val =mean_squared_error(y_val_scl, model_2_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9c57da",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
